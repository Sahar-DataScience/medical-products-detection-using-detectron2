{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWa5EuSjjbvZ"
      },
      "source": [
        "##**installing pytorch and detectron2** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaR-HLxwPXcq"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpvSUefLPYW5"
      },
      "outputs": [],
      "source": [
        "!pip install detectron2==0.6 -f \\\n",
        "https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijcE20kamL-t",
        "outputId": "ae93e262-da2d-45b7-a45d-c2e02d55c64a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RswUL1YOZEp",
        "outputId": "bae1e4b6-c0ad-4844-91a6-10597829cf2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n",
            "torch:  1.10 ; cuda:  cu111\n",
            "detectron2: 0.6\n",
            "1.10.1+cu111 True\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer , ColorMode, _create_text_labels\n",
        "from detectron2.utils.colormap import random_color\n",
        "\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wiVZvH9TEY7M"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv2\n",
        "import os , random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import PIL \n",
        "import numpy as np\n",
        "import json\n",
        "import glob\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lmmrw68Tn3RH"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content/drive/MyDrive/pharmacy/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M8d3MvH_npjA",
        "outputId": "e46658a9-5347-444b-8760-59b8c2ae757e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1of130zC4WOxL1MV2r7snVPEROqNr9fgT/pharmacy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6dzN02Qqrdv"
      },
      "outputs": [],
      "source": [
        "DatasetCatalog.clear()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9TLNZwEqDZZ"
      },
      "source": [
        "## **Register dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HT8Upz-KTned"
      },
      "outputs": [],
      "source": [
        "def get_dataset_dicts(p):\n",
        "  with open(p+\".json\",\"r\") as f:\n",
        "    data_dict = json.load(f)\n",
        "  return data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XA61E5gApKig"
      },
      "outputs": [],
      "source": [
        "d=\"syn_testset\"\n",
        "DatasetCatalog.register( d, lambda d=d: get_dataset_dicts(\"./data/\" + d))\n",
        "MetadataCatalog.get( d).set(thing_classes=['cycloff', 'bibron', 'cortéma', 'laroche_posay','soulagel', 'sucette'])\n",
        "test_metadata = MetadataCatalog.get(\"syn_testset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xuhsb6pcPdmL"
      },
      "outputs": [],
      "source": [
        "for d in [\"synthetic_train\", \"synthetic_test\"]:\n",
        "    DatasetCatalog.register(\"\" + d, lambda d=d: get_dataset_dicts(\"./data/\" + d))\n",
        "    MetadataCatalog.get(\"\" + d).set(thing_classes=['cycloff', 'bibron', 'cortéma', 'laroche_posay','soulagel', 'sucette'])\n",
        "train_metadata = MetadataCatalog.get(\"synthetic_train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5KgBNc4DXjZ"
      },
      "outputs": [],
      "source": [
        "#data_train_name = \"synthetic_train\"\n",
        "#data_test_name =\"synthetic_test\"\n",
        "#data_test_name =\"test\"\n",
        "data_test_name =\"syn_testset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ouiBvKYObPe"
      },
      "outputs": [],
      "source": [
        "cfg = get_cfg()\n",
        "cfg.OUTPUT_DIR = \"./logs\"\n",
        "\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
        "#cfg.MODEL.WEIGHTS = \"./model_0005247.pth\"\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster (default: 512)\n",
        "#cfg.DATASETS.TRAIN = (data_train_name,)\n",
        "cfg.DATASETS.TEST = (data_test_name,)\n",
        "# (\"fashion_train\",)\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = 800\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = 800\n",
        "\n",
        "cfg.INPUT.MIN_SIZE_TEST = 800\n",
        "# Maximum size of the side of the image during testing\n",
        "cfg.INPUT.MAX_SIZE_TEST = 800\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "\n",
        "cfg.SOLVER.BASE_LR = 0.001  \n",
        "# pick a good LR\n",
        "\n",
        "cfg.SOLVER.MAX_ITER = 63012 #21471 #35693 #142075  #2160\n",
        "# The iteration number to decrease learning rate by GAMMA. to decay lr (12,17)\n",
        "cfg.SOLVER.STEPS = (58000,)\n",
        "cfg.SOLVER.gamma = 0.5\n",
        "cfg.SOLVER.IMS_PER_BATCH = 8\n",
        "# after each epc        # do not decay learning rate\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD =  630 #356 #1420 #215 #  36*2\n",
        "\n",
        "#cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6\n",
        "#cfg.TEST.EVAL_PERIOD = 2840\n",
        "#cfg.TEST.DETECTIONS_PER_IMAGE = 50\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "cfg.MODEL.DEVICE = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoAZURZoNI4Y"
      },
      "outputs": [],
      "source": [
        "train_metadata = MetadataCatalog.get(data_train_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obNihDSpD1Ng"
      },
      "outputs": [],
      "source": [
        "test_metadata = MetadataCatalog.get(data_test_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZRrK1cSyIoN",
        "outputId": "f9788596-1409-4760-8a6b-c3533d87ba38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'file_name': './data/test_synthetic/1000.jpg',\n",
              " 'height': 2100,\n",
              " 'width': 2400,\n",
              " 'image_id': 1000,\n",
              " 'annotations': [{'iscrowd': 0,\n",
              "   'bbox': [332, 319, 1869, 1770],\n",
              "   'category_id': 1,\n",
              "   'bbox_mode': 0}]}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict_test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmd6jl45ylpu"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/pharmacy/data/synthetic_test.json','w') as ap:\n",
        "  json.dump(dict_test,ap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RepEaxfyxxtd",
        "outputId": "4f00c580-21de-4554-d9ad-b03fe1999e78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dict_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Saj3W-MhTMTs",
        "outputId": "c437074b-1062-40ec-cc37-1462c152af9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['cycloff', 'bibron', 'cortéma', 'laroche_posay', 'soulagel', 'sucette']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#train_metadata.thing_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT9-hAVATXe7",
        "outputId": "e8bfa42b-9265-46a6-f60d-d631f810644a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "464"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(DatasetCatalog.get(data_test_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE2Wa3xp5tly",
        "outputId": "66cfc865-687a-46e9-8157-d0ab7bf25787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[10/21 07:32:29 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
            "\u001b[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "|    cycloff    | 10           |   bibron   | 28           |  cortéma   | 25           |\n",
            "| laroche_posay | 45           |  soulagel  | 35           |  sucette   | 10           |\n",
            "|               |              |            |              |            |              |\n",
            "|     total     | 153          |            |              |            |              |\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "detectron2.data.print_instances_class_histogram(dict_test, test_metadata.thing_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1JU6Z5qOCAV",
        "outputId": "c5c89fc4-89eb-4bc1-dcc8-8e57b826199c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[10/20 00:10:12 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
            "\u001b[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "|    cycloff    | 334          |   bibron   | 802          |  cortéma   | 838          |\n",
            "| laroche_posay | 1463         |  soulagel  | 1194         |  sucette   | 394          |\n",
            "|               |              |            |              |            |              |\n",
            "|     total     | 5025         |            |              |            |              |\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "detectron2.data.print_instances_class_histogram(dict_train, train_metadata.thing_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMqhb6Vc_L_b",
        "outputId": "16dc03b2-c937-43dd-fed5-cc4f23a10764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "630.125\n",
            "63012.5\n",
            "31506.25\n"
          ]
        }
      ],
      "source": [
        "it_epoch = 5025/8\n",
        "print(it_epoch+2)\n",
        "max_it = (it_epoch+2) * 100\n",
        "print(max_it)\n",
        "print(max_it/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sooSsgfynjmv"
      },
      "outputs": [],
      "source": [
        "#for i in range(len(dict_train)):\n",
        "#  im = Image.open(dict_train[i]['file_name'])\n",
        "#  width, height = im.size\n",
        "#  dict_train[i]['height'] = height\n",
        "#  dict_train[i]['width'] = width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yQ3tDGFJG6k",
        "outputId": "19b512ef-256c-4182-f87f-c7923fdf0192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[10/12 07:43:08 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'data_test' to COCO format ...\n",
            "\u001b[32m[10/12 07:43:08 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'data_test' to COCO format ...)\n",
            "\u001b[32m[10/12 07:43:08 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[10/12 07:43:08 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 54, #annotations: 54\n",
            "\u001b[32m[10/12 07:43:08 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './data_test_coco_format.json' ...\n"
          ]
        }
      ],
      "source": [
        "evaluator = COCOEvaluator(data_test_name,tasks=(\"bbox\",),output_dir=\"./\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmUFf7mBgVTQ",
        "outputId": "bd3cfd5c-cca2-4117-e543-e290855b3915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Oct 20 05:50:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnKG8eLKmxMi"
      },
      "source": [
        " ## **simple training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vkSkvNrtmWRX"
      },
      "outputs": [],
      "source": [
        "trainer = DefaultTrainer(cfg)\n",
        "#model = trainer.build_model(cfg)\n",
        "#trainer.test(cfg, model,evaluators=evaluator)\n",
        "trainer.resume_or_load(resume = False) # load last checkpoint or MODEL.WEIGHTS\n",
        "#trainer.build_evaluator \n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_s_0GnDvvOS"
      },
      "source": [
        "##**Data augmenattion**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc-oXrnuOnjR"
      },
      "outputs": [],
      "source": [
        "from detectron2.data import detection_utils as utils\n",
        "import detectron2.data.transforms as T\n",
        "import copy\n",
        "\n",
        "def custom_mapper(dataset_dict):\n",
        "    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
        "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
        "    transform_list = [\n",
        "        T.Resize((800,800)),\n",
        "       #T.RandomRotation(angle=[20,60],expand=True, center=[[300,300],[465,1600]],sample_style='range'),\n",
        "      #  T.RandomFlip(prob=0.2, horizontal=False, vertical=True),\n",
        "    ]\n",
        "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
        "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
        "\n",
        "    annos = [\n",
        "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
        "        for obj in dataset_dict.pop(\"annotations\")\n",
        "        if obj.get(\"iscrowd\", 0) == 0\n",
        "    ]\n",
        "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
        "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
        "    return dataset_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVrB9n-_v_UZ"
      },
      "source": [
        "**custom training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO2rY4Luv-U4"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
        "\n",
        "class CustomTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
        "#%%\n",
        "trainer = CustomTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBGotk7fOrpx"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVCJ1xI7sZoy"
      },
      "source": [
        "#### custom mapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePbsEDXjVjRu"
      },
      "outputs": [],
      "source": [
        "####### Sauter #######\n",
        "####### Data augmentation ##############\n",
        "from detectron2.data import detection_utils as utils\n",
        "import detectron2.data.transforms as T\n",
        "#import detectron2.data.transforms.Augmentation as A\n",
        "import copy\n",
        "def custom_mapper(dataset_dict, pad, angle):\n",
        "    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
        "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
        "    w,h = image.shape[:2]\n",
        "    transform_list = [\n",
        "        T.NoOpTransform(),\n",
        "        #T.RandomFlip(prob=1, horizontal=False, vertical=True),\n",
        "        #T.RandomRotation(angle=[angle],expand=True,sample_style='choice', center=None),\n",
        "        #T.PadTransform(0,0,pad,pad,0),\n",
        "        #T.Resize((h,w)),\n",
        "        #T.RandomLighting(0.5),\n",
        "        ]\n",
        "        #T.RandomFlip(prob=0.7, horizontal=False, vertical=True),\n",
        "       # T.RandomFlip(prob=0.7, horizontal=True, vertical=False),]\n",
        "   \n",
        "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
        "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
        "\n",
        "    annos = [\n",
        "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
        "        for obj in dataset_dict.pop(\"annotations\")\n",
        "        if obj.get(\"iscrowd\", 0) == 0\n",
        "    ]\n",
        "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
        "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
        "    return dataset_dict , image"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QnKG8eLKmxMi",
        "0_s_0GnDvvOS"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}